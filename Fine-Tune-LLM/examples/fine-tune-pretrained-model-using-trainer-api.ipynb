{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Fine_tune_pretrained_model_using_Trainer_API for supervised Task","metadata":{"_uuid":"f248f36b-8ec1-45b3-a362-fc98d991239d","_cell_guid":"7900468e-a11e-4b58-8d0b-dd4ccb11490f","trusted":true}},{"cell_type":"markdown","source":"## 1. Prepare the Dataset","metadata":{"_uuid":"a4766438-bead-41a4-86b9-e5c31f54a681","_cell_guid":"13ba2766-351b-46c2-8a3c-ea276c879dbe","trusted":true}},{"cell_type":"code","source":"from datasets import load_dataset\nfrom transformers import AutoTokenizer, DataCollatorWithPadding\n\nraw_datasets_tweets = load_dataset(\"tweet_eval\",\"emoji\")\ncheckpoint = \"bert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\n\nraw_train_datasets_small = raw_datasets_tweets[\"train\"].select(range(8000))\nraw_validaion_datasets_small = raw_datasets_tweets[\"validation\"].select(range(2000))\nraw_test_datasets_small = raw_datasets_tweets[\"test\"].select(range(2000))\n\ndef tokenize_function(example):\n    return tokenizer(example[\"text\"],padding=True, truncation=True)\n\n\ntokenized_train_datasets_tweets = raw_train_datasets_small.map(tokenize_function, batched=True)\ntokenized_validaion_datasets_tweets = raw_validaion_datasets_small.map(tokenize_function, batched=True)\ntokenized_test_datasets_tweets = raw_test_datasets_small.map(tokenize_function, batched=True)","metadata":{"_uuid":"38452f2c-c8b5-4c44-b100-068900e492e7","_cell_guid":"f1be5f95-eaab-403a-8c3c-af554c8a565e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-17T17:18:45.176112Z","iopub.execute_input":"2024-02-17T17:18:45.176472Z","iopub.status.idle":"2024-02-17T17:18:47.144845Z","shell.execute_reply.started":"2024-02-17T17:18:45.176426Z","shell.execute_reply":"2024-02-17T17:18:47.143995Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c97a3568123043e8aa9303d9b7817726"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/8 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f40023d9bd7e45cda2b699a2c43a1c0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"585b85f12699459da69589ba7f897777"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92ba04a0240f4a1093f488f9a46c59e8"}},"metadata":{}}]},{"cell_type":"markdown","source":"## 3.using the Trainer API of the transformer Library","metadata":{"_uuid":"9de392ca-055e-4fc9-b6de-2d0cf9a82992","_cell_guid":"dfb72a4e-75e6-40a0-aa1e-f5692b032735","trusted":true}},{"cell_type":"markdown","source":"### 3.1 Define Training args","metadata":{"_uuid":"0541b394-b209-4ad6-b45f-22cd6a96006d","_cell_guid":"b6e7dc7a-6875-40f7-ac27-b146f0e55c4b","trusted":true}},{"cell_type":"code","source":"from transformers import TrainingArguments\ntraining_args = TrainingArguments(\"test-trainer\",report_to=\"none\")","metadata":{"_uuid":"97fb7758-ac78-4b13-9cbe-fd1b9ed4ecb9","_cell_guid":"8b1ab4ab-ed8f-4804-8b7a-14b177efd2a2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-17T17:23:52.196979Z","iopub.execute_input":"2024-02-17T17:23:52.198045Z","iopub.status.idle":"2024-02-17T17:23:52.202674Z","shell.execute_reply.started":"2024-02-17T17:23:52.198007Z","shell.execute_reply":"2024-02-17T17:23:52.201724Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"### 3.2 Define the Model","metadata":{"_uuid":"79d89c88-75a7-4116-ac12-6a9013d65700","_cell_guid":"52419e8d-67fe-4459-9d0a-2ab38eeeaa28","trusted":true}},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\nmodel = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=20)","metadata":{"_uuid":"3bd5a855-005f-45bb-aee9-f02cf223d261","_cell_guid":"dc993704-3681-48a5-abf6-9d2d6ed4b146","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-17T17:23:54.619947Z","iopub.execute_input":"2024-02-17T17:23:54.620846Z","iopub.status.idle":"2024-02-17T17:23:54.965166Z","shell.execute_reply.started":"2024-02-17T17:23:54.620803Z","shell.execute_reply":"2024-02-17T17:23:54.964270Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 3.3 Define a Trainer","metadata":{"_uuid":"d063d2e2-49ed-48d1-835d-61d64e6044ef","_cell_guid":"663682da-611c-4886-808d-80854d323652","trusted":true}},{"cell_type":"code","source":"from transformers import Trainer\ntrainer = Trainer(\n    model,\n    training_args,\n    train_dataset=tokenized_train_datasets_tweets,\n    eval_dataset=tokenized_validaion_datasets_tweets,\n    tokenizer=tokenizer,\n)","metadata":{"_uuid":"bdaaa615-1a53-4135-97a1-7684859e43a8","_cell_guid":"a5f64746-e9d6-45d9-a21e-c3ea8dc7bbe2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-17T17:23:58.192424Z","iopub.execute_input":"2024-02-17T17:23:58.193313Z","iopub.status.idle":"2024-02-17T17:23:58.312465Z","shell.execute_reply.started":"2024-02-17T17:23:58.193281Z","shell.execute_reply":"2024-02-17T17:23:58.311703Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"### 3.4 Launch the training","metadata":{}},{"cell_type":"code","source":"trainer.train()","metadata":{"_uuid":"c0d4942b-8bb4-438d-84b7-2edcaa812f47","_cell_guid":"b295ea97-f765-4608-a3c5-62fded313b18","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-17T17:24:00.751581Z","iopub.execute_input":"2024-02-17T17:24:00.752219Z","iopub.status.idle":"2024-02-17T17:29:05.835076Z","shell.execute_reply.started":"2024-02-17T17:24:00.752187Z","shell.execute_reply":"2024-02-17T17:29:05.834210Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1500/1500 05:01, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>2.578200</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>2.123400</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>1.689300</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1500, training_loss=2.1302825520833335, metrics={'train_runtime': 304.7252, 'train_samples_per_second': 78.759, 'train_steps_per_second': 4.922, 'total_flos': 773901778653696.0, 'train_loss': 2.1302825520833335, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"### 3.5 inference from the trainer ","metadata":{}},{"cell_type":"code","source":"from datasets import Dataset\ndef predict(element, trainer, tokenizer, datasetlabel):\n    # Tokenize the input\n    inputs = tokenizer(element, padding=True, truncation=True, return_tensors=\"pt\")\n    # Convert to a format compatible with the Trainer API (wrap as a dataset)\n    dataset = Dataset.from_dict({key: value.numpy() for key, value in inputs.items()})\n    predictions = trainer.predict(dataset)\n    predicted_label_index = predictions.predictions.argmax(-1)\n    return datasetlabel[predicted_label_index[0]]\n\nvalue = predict(\"I will take a photo.\",trainer, tokenizer, raw_train_datasets_small.features['label'].names)\nprint(value)","metadata":{"execution":{"iopub.status.busy":"2024-02-17T18:31:41.822060Z","iopub.execute_input":"2024-02-17T18:31:41.822829Z","iopub.status.idle":"2024-02-17T18:31:41.867128Z","shell.execute_reply.started":"2024-02-17T18:31:41.822794Z","shell.execute_reply":"2024-02-17T18:31:41.866285Z"},"trusted":true},"execution_count":58,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"ðŸ“¸\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 4.Saving and Sharing your model","metadata":{}},{"cell_type":"markdown","source":"### 4.1 Save the Model Locally","metadata":{}},{"cell_type":"code","source":"# Save the model and the tokenizer to a directory\nmodel_save_path = \"/kaggle/working/models\"\ntrainer.save_model(model_save_path)","metadata":{"execution":{"iopub.status.busy":"2024-02-17T18:36:46.784814Z","iopub.execute_input":"2024-02-17T18:36:46.785693Z","iopub.status.idle":"2024-02-17T18:36:47.468705Z","shell.execute_reply.started":"2024-02-17T18:36:46.785660Z","shell.execute_reply":"2024-02-17T18:36:47.467682Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":"### 4.2 Load a local Model ","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, AutoTokenizer\n\n# Set the path to your model directory\nmodel_directory = \"/kaggle/working/models\" \n\n# Load the trained model\nmodel = AutoModelForSequenceClassification.from_pretrained(model_directory)\n\n# Load the tokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_directory)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-17T18:36:49.703843Z","iopub.execute_input":"2024-02-17T18:36:49.704662Z","iopub.status.idle":"2024-02-17T18:36:49.949909Z","shell.execute_reply.started":"2024-02-17T18:36:49.704635Z","shell.execute_reply":"2024-02-17T18:36:49.949135Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"### 4.3 Apply inference using the transformer pipeline class","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n\n# Set the path to your model directory\nmodel_directory = \"/kaggle/working/models\"  # Update this to your directory path\n\n# Create a pipeline for text classification\n# Make sure to specify the correct task if it's different (e.g., sentiment-analysis, token-classification, etc.)\ntext_classification_pipeline = pipeline(\n    \"text-classification\",\n    model=model_directory,\n    tokenizer=model_directory\n)\n\nnum_labels = model.config.num_labels\nprint(f\"This model can predict {num_labels} different labels.\")\n\n# Text to classify\ntext = \"I will take a photo.\"\n# Perform inference\nresult = text_classification_pipeline(text)\n# The result will be a list with a dictionary for each text classified\n# If you provided a single text, you can just access the first result\nprint(result)\n# To get the predicted label and score\npredicted_label = result[0]['label']\nconfidence_score = result[0]['score']\nprint(f\"Predicted label: {predicted_label}\")\nprint(f\"Confidence score: {confidence_score}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-02-17T18:36:52.177606Z","iopub.execute_input":"2024-02-17T18:36:52.178643Z","iopub.status.idle":"2024-02-17T18:36:52.653937Z","shell.execute_reply.started":"2024-02-17T18:36:52.178594Z","shell.execute_reply":"2024-02-17T18:36:52.652973Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"This model can predict 20 different labels.\n[{'label': 'LABEL_18', 'score': 0.30742329359054565}]\nPredicted label: LABEL_18\nConfidence score: 0.30742329359054565\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-02-17T18:54:36.382522Z","iopub.execute_input":"2024-02-17T18:54:36.382924Z","iopub.status.idle":"2024-02-17T18:54:36.409882Z","shell.execute_reply.started":"2024-02-17T18:54:36.382891Z","shell.execute_reply":"2024-02-17T18:54:36.408833Z"},"trusted":true},"execution_count":62,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a4e3057df8143888bd0b4917d09f85c"}},"metadata":{}}]},{"cell_type":"code","source":"trainer.push_to_hub()","metadata":{"execution":{"iopub.status.busy":"2024-02-17T18:56:04.727489Z","iopub.execute_input":"2024-02-17T18:56:04.728157Z","iopub.status.idle":"2024-02-17T18:56:22.080684Z","shell.execute_reply.started":"2024-02-17T18:56:04.728125Z","shell.execute_reply":"2024-02-17T18:56:22.079737Z"},"trusted":true},"execution_count":63,"outputs":[{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/4.66k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2d97a376bd84e21a4d00dd2af6d276a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecfc1cd18df44bf6b380114100b8d226"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1708190350.7b303a7d903d.34.0:   0%|          | 0.00/5.18k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f21451b349a4507a3d7d51577bb65d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb72653c08a947ee8ad86cfe5a0d8ee4"}},"metadata":{}},{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/msehsah/test-trainer/commit/4e8e71cc347419bd73a4e341320723f0c86d91e1', commit_message='End of training', commit_description='', oid='4e8e71cc347419bd73a4e341320723f0c86d91e1', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]}]}